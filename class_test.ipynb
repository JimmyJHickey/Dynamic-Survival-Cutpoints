{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/5364050/reloading-submodules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from multilevel_cutpoint_model import CutpointModel\n",
    "# from multilevel_cutpoint_model import discrete_ci\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from node import Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_moon indicates if the data will be in the first bucket or the second\n",
    "N = 10000\n",
    "X, y_moon = make_moons(n_samples = N, noise=0.3, random_state=1978)\n",
    "\n",
    "# drop 1/2 of the 1 moons \n",
    "# want y_moon plot to look even and censoring to look even\n",
    "# try higher value of sigmoid if it can't find the cutpoint\n",
    "combined = np.append(X, y_moon[:,None], 1)\n",
    "combined_sorted = combined[combined[:, -1].argsort()]\n",
    "combined_sorted = combined_sorted[:7500,:]\n",
    "np.random.shuffle(combined_sorted)\n",
    "X = combined_sorted[:,:-1]\n",
    "y_moon = combined_sorted[:,-1]\n",
    "\n",
    "t_min = 0\n",
    "t_boundary = 67\n",
    "t_max = 100\n",
    "t = np.zeros(len(y_moon))\n",
    "\n",
    "# s = np.random.binomial(1, 0.5, len(y_moon))\n",
    "s = np.random.binomial(1, 1, len(y_moon))\n",
    "\n",
    "for ii in range(0, len(y_moon)):\n",
    "    if y_moon[ii] == 0:\n",
    "        t[ii] = np.random.uniform(t_min, t_boundary)\n",
    "    elif y_moon[ii] == 1:\n",
    "        \n",
    "        t[ii] = np.random.uniform(t_boundary, t_max)\n",
    "        \n",
    "# t = t[1:int(N * 3/4)]\n",
    "# s = s[1:int(N * 3/4)]\n",
    "# y_moon = y_moon[1:int(N * 3/4)]\n",
    "# X = X[1:int(N * 3/4), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(t[y_moon==0], bins=50, alpha = 0.5, color = \"blue\", label=\"clust1\")\n",
    "plt.hist(t[y_moon==1], bins=25, alpha = 0.5, color = \"red\", label=\"clust2\")\n",
    "plt.axvline(t_boundary, color=\"black\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(t[s==0], bins=50, alpha = 0.5, color = \"blue\", label=\"censor\")\n",
    "plt.hist(t[s==1], bins=50, alpha = 0.5, color = \"red\", label=\"endpoint\")\n",
    "plt.axvline(67, color=\"black\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, \\\n",
    "t_train, t_test,\\\n",
    "s_train, s_test = train_test_split(\n",
    "    X, t, s, test_size=0.2, random_state=1978\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "loss 1.001237154006958\n",
      "cutpoint 0.25\n",
      "2\n",
      "loss 0.9790000915527344\n",
      "cutpoint 0.25999999046325684\n",
      "3\n",
      "loss 0.9650987386703491\n",
      "cutpoint 0.26133865118026733\n",
      "4\n",
      "loss 0.9513014554977417\n",
      "cutpoint 0.25834617018699646\n",
      "5\n",
      "loss 0.937042772769928\n",
      "cutpoint 0.2594354748725891\n",
      "6\n",
      "loss 0.9246070981025696\n",
      "cutpoint 0.2576104998588562\n",
      "7\n",
      "loss 0.9108921885490417\n",
      "cutpoint 0.2626447379589081\n",
      "8\n",
      "loss 0.898074209690094\n",
      "cutpoint 0.26552969217300415\n",
      "9\n",
      "loss 0.8850840330123901\n",
      "cutpoint 0.2682426869869232\n",
      "10\n",
      "loss 0.8715891242027283\n",
      "cutpoint 0.2725366950035095\n",
      "11\n",
      "loss 0.8593551516532898\n",
      "cutpoint 0.27432411909103394\n",
      "12\n",
      "loss 0.8475879430770874\n",
      "cutpoint 0.27792632579803467\n",
      "13\n",
      "loss 0.8374761939048767\n",
      "cutpoint 0.28125080466270447\n",
      "14\n",
      "loss 0.8269898891448975\n",
      "cutpoint 0.284457266330719\n",
      "15\n",
      "loss 0.8170027732849121\n",
      "cutpoint 0.2864472270011902\n",
      "16\n",
      "loss 0.8074710369110107\n",
      "cutpoint 0.2894458770751953\n",
      "17\n",
      "loss 0.7994316816329956\n",
      "cutpoint 0.2927216589450836\n",
      "18\n",
      "loss 0.7914203405380249\n",
      "cutpoint 0.2956475019454956\n",
      "19\n",
      "loss 0.7841333150863647\n",
      "cutpoint 0.2975659966468811\n",
      "20\n",
      "loss 0.776154637336731\n",
      "cutpoint 0.2979312539100647\n",
      "21\n",
      "loss 0.7680881023406982\n",
      "cutpoint 0.2985340654850006\n",
      "22\n",
      "loss 0.7606368660926819\n",
      "cutpoint 0.29946503043174744\n",
      "23\n",
      "loss 0.7530142664909363\n",
      "cutpoint 0.29871803522109985\n",
      "24\n",
      "loss 0.7459696531295776\n",
      "cutpoint 0.2980523109436035\n",
      "25\n",
      "loss 0.7390030026435852\n",
      "cutpoint 0.29796525835990906\n",
      "26\n",
      "loss 0.732180655002594\n",
      "cutpoint 0.29811856150627136\n",
      "27\n",
      "loss 0.7254906892776489\n",
      "cutpoint 0.29879528284072876\n",
      "28\n",
      "loss 0.7191867232322693\n",
      "cutpoint 0.299199640750885\n",
      "29\n",
      "loss 0.7129256725311279\n",
      "cutpoint 0.2990161180496216\n",
      "30\n",
      "loss 0.7068511843681335\n",
      "cutpoint 0.2983587384223938\n",
      "31\n",
      "loss 0.7010115385055542\n",
      "cutpoint 0.2982105612754822\n",
      "32\n",
      "loss 0.6952275037765503\n",
      "cutpoint 0.2986004054546356\n",
      "33\n",
      "loss 0.6897239089012146\n",
      "cutpoint 0.298917293548584\n",
      "34\n",
      "loss 0.6842900514602661\n",
      "cutpoint 0.29871082305908203\n",
      "35\n",
      "loss 0.6790907979011536\n",
      "cutpoint 0.29824262857437134\n",
      "36\n",
      "loss 0.6739704608917236\n",
      "cutpoint 0.29834139347076416\n",
      "37\n",
      "loss 0.6690458655357361\n",
      "cutpoint 0.2988946735858917\n",
      "38\n",
      "loss 0.6642447710037231\n",
      "cutpoint 0.298898845911026\n",
      "39\n",
      "loss 0.6595412492752075\n",
      "cutpoint 0.298393577337265\n",
      "40\n",
      "loss 0.6550284624099731\n",
      "cutpoint 0.2983314096927643\n",
      "41\n",
      "loss 0.6506376266479492\n",
      "cutpoint 0.29875388741493225\n",
      "42\n",
      "loss 0.6463718414306641\n",
      "cutpoint 0.29871058464050293\n",
      "43\n",
      "loss 0.6422716975212097\n",
      "cutpoint 0.2982480227947235\n",
      "44\n",
      "loss 0.6382404565811157\n",
      "cutpoint 0.29837459325790405\n",
      "45\n",
      "loss 0.6344178318977356\n",
      "cutpoint 0.29891979694366455\n",
      "46\n",
      "loss 0.6306520104408264\n",
      "cutpoint 0.29886943101882935\n",
      "47\n",
      "loss 0.6269861459732056\n",
      "cutpoint 0.2983193099498749\n",
      "48\n",
      "loss 0.6234645843505859\n",
      "cutpoint 0.29832935333251953\n",
      "49\n",
      "loss 0.6200873255729675\n",
      "cutpoint 0.2988390624523163\n",
      "50\n",
      "loss 0.6167862415313721\n",
      "cutpoint 0.2988092005252838\n",
      "51\n",
      "loss 0.6135854721069336\n",
      "cutpoint 0.2982896864414215\n",
      "52\n",
      "loss 0.6104847192764282\n",
      "cutpoint 0.2983688712120056\n",
      "53\n",
      "loss 0.6075559258460999\n",
      "cutpoint 0.29889434576034546\n",
      "54\n",
      "loss 0.6046679019927979\n",
      "cutpoint 0.2988646626472473\n",
      "55\n",
      "loss 0.6018409729003906\n",
      "cutpoint 0.29834437370300293\n",
      "56\n",
      "loss 0.5991417169570923\n",
      "cutpoint 0.29837343096733093\n",
      "57\n",
      "loss 0.5965842008590698\n",
      "cutpoint 0.2988540530204773\n",
      "58\n",
      "loss 0.5940577983856201\n",
      "cutpoint 0.2988041937351227\n",
      "59\n",
      "loss 0.5916184186935425\n",
      "cutpoint 0.29825305938720703\n",
      "60\n",
      "loss 0.5892415642738342\n",
      "cutpoint 0.29836171865463257\n",
      "61\n",
      "loss 0.5870310664176941\n",
      "cutpoint 0.298944890499115\n",
      "62\n",
      "loss 0.5848456025123596\n",
      "cutpoint 0.2990094721317291\n",
      "63\n",
      "loss 0.5826388597488403\n",
      "cutpoint 0.2986202836036682\n",
      "64\n",
      "loss 0.580663800239563\n",
      "cutpoint 0.29781776666641235\n",
      "65\n",
      "loss 0.5778968930244446\n",
      "cutpoint 0.29626765847206116\n",
      "66\n",
      "loss 0.5750530958175659\n",
      "cutpoint 0.29379045963287354\n",
      "67\n",
      "loss 0.5720325112342834\n",
      "cutpoint 0.2917579710483551\n",
      "68\n",
      "loss 0.5685774683952332\n",
      "cutpoint 0.2889305651187897\n",
      "69\n",
      "loss 0.5660926103591919\n",
      "cutpoint 0.2854430079460144\n",
      "70\n",
      "loss 0.562001645565033\n",
      "cutpoint 0.28048115968704224\n",
      "71\n",
      "loss 0.5579442381858826\n",
      "cutpoint 0.27618834376335144\n",
      "72\n",
      "loss 0.5548494458198547\n",
      "cutpoint 0.270281046628952\n",
      "73\n",
      "loss 0.5519607067108154\n",
      "cutpoint 0.2638463079929352\n",
      "74\n",
      "loss 0.5466970205307007\n",
      "cutpoint 0.25544366240501404\n",
      "75\n",
      "loss 0.5432372093200684\n",
      "cutpoint 0.24804089963436127\n",
      "76\n",
      "loss 0.5398334264755249\n",
      "cutpoint 0.2417854517698288\n",
      "77\n",
      "loss 0.5360614657402039\n",
      "cutpoint 0.23648257553577423\n",
      "78\n",
      "loss 0.5319254994392395\n",
      "cutpoint 0.2298511266708374\n",
      "79\n",
      "loss 0.5282583832740784\n",
      "cutpoint 0.22360266745090485\n",
      "80\n",
      "loss 0.5237740874290466\n",
      "cutpoint 0.21827751398086548\n",
      "81\n",
      "loss 0.5210065245628357\n",
      "cutpoint 0.21311691403388977\n",
      "82\n",
      "loss 0.5156323313713074\n",
      "cutpoint 0.2079324871301651\n",
      "83\n",
      "loss 0.5103159546852112\n",
      "cutpoint 0.20233428478240967\n",
      "84\n",
      "loss 0.5071648359298706\n",
      "cutpoint 0.19677333533763885\n",
      "85\n",
      "loss 0.5008866786956787\n",
      "cutpoint 0.1913129687309265\n",
      "86\n",
      "loss 0.4973476827144623\n",
      "cutpoint 0.18586945533752441\n",
      "87\n",
      "loss 0.49018314480781555\n",
      "cutpoint 0.17952539026737213\n",
      "88\n",
      "loss 0.4880261719226837\n",
      "cutpoint 0.1731128841638565\n",
      "89\n",
      "loss 0.4842076003551483\n",
      "cutpoint 0.16790616512298584\n",
      "90\n",
      "loss 0.477965772151947\n",
      "cutpoint 0.16117003560066223\n",
      "91\n",
      "loss 0.4737659990787506\n",
      "cutpoint 0.15411947667598724\n",
      "92\n",
      "loss 0.4686621129512787\n",
      "cutpoint 0.14715108275413513\n",
      "93\n",
      "loss 0.4648255407810211\n",
      "cutpoint 0.1419248878955841\n",
      "94\n",
      "loss 0.46234560012817383\n",
      "cutpoint 0.1376190483570099\n",
      "95\n",
      "loss 0.4588218927383423\n",
      "cutpoint 0.13407333195209503\n",
      "96\n",
      "loss 0.4548848569393158\n",
      "cutpoint 0.13102267682552338\n",
      "97\n",
      "loss 0.4521303176879883\n",
      "cutpoint 0.12861815094947815\n",
      "98\n",
      "loss 0.4495544135570526\n",
      "cutpoint 0.12857666611671448\n",
      "99\n",
      "loss 0.44737616181373596\n",
      "cutpoint 0.1305629163980484\n",
      "100\n",
      "loss 0.44527482986450195\n",
      "cutpoint 0.13253876566886902\n",
      "101\n",
      "loss 0.4437682032585144\n",
      "cutpoint 0.13331207633018494\n",
      "102\n",
      "loss 0.4413239657878876\n",
      "cutpoint 0.13091275095939636\n",
      "103\n",
      "loss 0.43912264704704285\n",
      "cutpoint 0.12947195768356323\n",
      "104\n",
      "loss 0.4381144046783447\n",
      "cutpoint 0.1279255598783493\n",
      "105\n",
      "loss 0.43515050411224365\n",
      "cutpoint 0.1255200058221817\n",
      "106\n",
      "loss 0.429842472076416\n",
      "cutpoint 0.12040625512599945\n",
      "107\n",
      "loss 0.4259617030620575\n",
      "cutpoint 0.11356459558010101\n",
      "108\n",
      "loss 0.42362862825393677\n",
      "cutpoint 0.10960114002227783\n",
      "109\n",
      "loss 0.4196985363960266\n",
      "cutpoint 0.106378935277462\n",
      "110\n",
      "loss 0.41821974515914917\n",
      "cutpoint 0.10322305560112\n",
      "111\n",
      "loss 0.41657426953315735\n",
      "cutpoint 0.09819763153791428\n",
      "112\n",
      "loss 0.413516104221344\n",
      "cutpoint 0.09015635401010513\n",
      "113\n",
      "loss 0.40905600786209106\n",
      "cutpoint 0.08067160844802856\n",
      "114\n",
      "loss 0.4084380269050598\n",
      "cutpoint 0.07175273448228836\n",
      "115\n",
      "loss 0.4086177945137024\n",
      "cutpoint 0.06484393030405045\n",
      "116\n",
      "loss 0.4110373854637146\n",
      "cutpoint 0.05941976606845856\n",
      "117\n",
      "loss 0.40855157375335693\n",
      "cutpoint 0.05503286048769951\n",
      "118\n",
      "loss 0.4088307023048401\n",
      "cutpoint 0.05185893177986145\n",
      "119\n",
      "loss 0.4054892063140869\n",
      "cutpoint 0.0525895431637764\n",
      "120\n",
      "loss 0.40247058868408203\n",
      "cutpoint 0.0541352704167366\n",
      "121\n",
      "loss 0.40004289150238037\n",
      "cutpoint 0.05622616037726402\n",
      "122\n",
      "loss 0.3996846675872803\n",
      "cutpoint 0.0587371289730072\n",
      "123\n",
      "loss 0.39791402220726013\n",
      "cutpoint 0.05848288536071777\n",
      "124\n",
      "loss 0.3955174684524536\n",
      "cutpoint 0.05759883299469948\n",
      "125\n",
      "loss 0.39373379945755005\n",
      "cutpoint 0.05448925867676735\n",
      "126\n",
      "loss 0.39498746395111084\n",
      "cutpoint 0.05016602203249931\n",
      "127\n",
      "loss 0.39648857712745667\n",
      "cutpoint 0.04711592197418213\n",
      "128\n",
      "loss 0.40458136796951294\n",
      "cutpoint 0.04163501411676407\n",
      "129\n",
      "loss 0.40613889694213867\n",
      "cutpoint 0.04021739214658737\n",
      "130\n",
      "loss 0.40063732862472534\n",
      "cutpoint 0.04216688126325607\n",
      "131\n",
      "loss 0.39304330945014954\n",
      "cutpoint 0.04536297917366028\n",
      "132\n",
      "loss 0.3871549367904663\n",
      "cutpoint 0.05094306543469429\n",
      "133\n",
      "loss 0.3858951926231384\n",
      "cutpoint 0.05790942534804344\n",
      "134\n",
      "loss 0.38749194145202637\n",
      "cutpoint 0.06211348623037338\n",
      "135\n",
      "loss 0.3851630389690399\n",
      "cutpoint 0.06430262327194214\n",
      "136\n",
      "loss 0.38659578561782837\n",
      "cutpoint 0.06725597381591797\n",
      "137\n",
      "loss 0.3864033818244934\n",
      "cutpoint 0.06731753796339035\n",
      "138\n",
      "loss 0.38417816162109375\n",
      "cutpoint 0.0652216300368309\n",
      "139\n",
      "loss 0.3851217031478882\n",
      "cutpoint 0.06287916749715805\n",
      "140\n",
      "loss 0.3854091763496399\n",
      "cutpoint 0.06120627373456955\n",
      "141\n",
      "loss 0.3843831717967987\n",
      "cutpoint 0.05927697569131851\n",
      "142\n",
      "loss 0.3798421025276184\n",
      "cutpoint 0.0568605437874794\n",
      "143\n",
      "loss 0.37818393111228943\n",
      "cutpoint 0.05399557203054428\n",
      "144\n",
      "loss 0.379266619682312\n",
      "cutpoint 0.05104108899831772\n",
      "145\n",
      "loss 0.37866243720054626\n",
      "cutpoint 0.050351087003946304\n",
      "146\n",
      "loss 0.37975484132766724\n",
      "cutpoint 0.048080965876579285\n",
      "147\n",
      "loss 0.3794974684715271\n",
      "cutpoint 0.04698460176587105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n",
      "loss 0.38460347056388855\n",
      "cutpoint 0.043892912566661835\n",
      "149\n",
      "loss 0.381921648979187\n",
      "cutpoint 0.044774774461984634\n",
      "150\n",
      "loss 0.37815743684768677\n",
      "cutpoint 0.048205289989709854\n",
      "151\n",
      "loss 0.3755093812942505\n",
      "cutpoint 0.05256291851401329\n",
      "152\n",
      "loss 0.3767489790916443\n",
      "cutpoint 0.056138068437576294\n",
      "153\n",
      "loss 0.3799542486667633\n",
      "cutpoint 0.05846996232867241\n",
      "154\n",
      "loss 0.37994182109832764\n",
      "cutpoint 0.05855990946292877\n",
      "155\n",
      "loss 0.37650373578071594\n",
      "cutpoint 0.05668088421225548\n",
      "156\n",
      "loss 0.37474071979522705\n",
      "cutpoint 0.05433113873004913\n",
      "157\n",
      "loss 0.3753347396850586\n",
      "cutpoint 0.05108583718538284\n",
      "158\n",
      "loss 0.37515193223953247\n",
      "cutpoint 0.04973117262125015\n",
      "159\n",
      "loss 0.3747591972351074\n",
      "cutpoint 0.05044081062078476\n",
      "160\n",
      "loss 0.37463074922561646\n",
      "cutpoint 0.0488867349922657\n",
      "161\n",
      "loss 0.3742665946483612\n",
      "cutpoint 0.04900723695755005\n",
      "162\n",
      "loss 0.3742745816707611\n",
      "cutpoint 0.05048861354589462\n",
      "163\n",
      "loss 0.37432509660720825\n",
      "cutpoint 0.04959488660097122\n",
      "164\n",
      "loss 0.3739142417907715\n",
      "cutpoint 0.0493706576526165\n",
      "165\n",
      "loss 0.374332457780838\n",
      "cutpoint 0.046814046800136566\n",
      "166\n",
      "loss 0.38054439425468445\n",
      "cutpoint 0.0436021089553833\n",
      "167\n",
      "loss 0.3795742392539978\n",
      "cutpoint 0.04386194795370102\n",
      "168\n",
      "loss 0.3744868040084839\n",
      "cutpoint 0.047180235385894775\n",
      "169\n",
      "loss 0.3741365075111389\n",
      "cutpoint 0.04711765795946121\n",
      "170\n",
      "loss 0.37778711318969727\n",
      "cutpoint 0.04434926435351372\n",
      "171\n",
      "loss 0.3768375515937805\n",
      "cutpoint 0.04462689533829689\n",
      "172\n",
      "loss 0.3742527365684509\n",
      "cutpoint 0.04735518619418144\n",
      "173\n",
      "loss 0.3730553388595581\n",
      "cutpoint 0.04833805933594704\n",
      "174\n",
      "loss 0.3727695941925049\n",
      "cutpoint 0.05070258677005768\n",
      "175\n",
      "loss 0.3720162510871887\n",
      "cutpoint 0.05195767432451248\n",
      "176\n",
      "loss 0.3726089596748352\n",
      "cutpoint 0.05462731420993805\n",
      "177\n",
      "loss 0.3726043105125427\n",
      "cutpoint 0.05466412007808685\n",
      "178\n",
      "loss 0.3710692524909973\n",
      "cutpoint 0.05256638303399086\n",
      "179\n",
      "loss 0.3713941276073456\n",
      "cutpoint 0.0501788966357708\n",
      "180\n",
      "loss 0.3727360963821411\n",
      "cutpoint 0.047788191586732864\n",
      "181\n",
      "loss 0.3731493353843689\n",
      "cutpoint 0.047435641288757324\n",
      "182\n",
      "loss 0.37182268500328064\n",
      "cutpoint 0.04686903581023216\n",
      "183\n",
      "loss 0.3741162419319153\n",
      "cutpoint 0.04516633227467537\n",
      "184\n",
      "loss 0.3746679425239563\n",
      "cutpoint 0.04479580745100975\n",
      "185\n",
      "loss 0.371670126914978\n",
      "cutpoint 0.04638788476586342\n",
      "186\n",
      "loss 0.3706752061843872\n",
      "cutpoint 0.04918184503912926\n",
      "187\n",
      "loss 0.3712800443172455\n",
      "cutpoint 0.051105935126543045\n",
      "188\n",
      "loss 0.3706211447715759\n",
      "cutpoint 0.0538892038166523\n",
      "189\n",
      "loss 0.372295081615448\n",
      "cutpoint 0.055736761540174484\n",
      "190\n",
      "loss 0.37462329864501953\n",
      "cutpoint 0.05758343264460564\n",
      "191\n",
      "loss 0.3730427622795105\n",
      "cutpoint 0.056733496487140656\n",
      "192\n",
      "loss 0.3718505799770355\n",
      "cutpoint 0.05518009886145592\n",
      "193\n",
      "loss 0.36986035108566284\n",
      "cutpoint 0.05279489979147911\n",
      "194\n",
      "loss 0.3709196150302887\n",
      "cutpoint 0.050743218511343\n",
      "195\n",
      "loss 0.37090611457824707\n",
      "cutpoint 0.048228099942207336\n",
      "196\n",
      "loss 0.3704991340637207\n",
      "cutpoint 0.046859800815582275\n",
      "197\n",
      "loss 0.37426191568374634\n",
      "cutpoint 0.044478338211774826\n",
      "198\n",
      "loss 0.373063325881958\n",
      "cutpoint 0.04496091604232788\n",
      "199\n",
      "loss 0.37082505226135254\n",
      "cutpoint 0.04712655767798424\n",
      "200\n",
      "loss 0.37027764320373535\n",
      "cutpoint 0.046460460871458054\n",
      "201\n",
      "loss 0.3704124093055725\n",
      "cutpoint 0.047026146203279495\n",
      "202\n",
      "loss 0.3718531131744385\n",
      "cutpoint 0.045525871217250824\n",
      "203\n",
      "loss 0.3702773153781891\n",
      "cutpoint 0.04630585387349129\n",
      "204\n",
      "loss 0.37010347843170166\n",
      "cutpoint 0.048344217240810394\n",
      "205\n",
      "loss 0.36996203660964966\n",
      "cutpoint 0.05149123817682266\n",
      "206\n",
      "loss 0.3696042001247406\n",
      "cutpoint 0.05412593111395836\n",
      "207\n",
      "loss 0.37119215726852417\n",
      "cutpoint 0.05573980137705803\n",
      "208\n",
      "loss 0.3727937638759613\n",
      "cutpoint 0.05733206868171692\n",
      "209\n",
      "loss 0.37150752544403076\n",
      "cutpoint 0.05620652437210083\n",
      "210\n",
      "loss 0.3696223795413971\n",
      "cutpoint 0.05435989424586296\n",
      "211\n",
      "loss 0.3695961534976959\n",
      "cutpoint 0.05144504830241203\n",
      "212\n",
      "loss 0.3694140315055847\n",
      "cutpoint 0.04846362769603729\n",
      "213\n",
      "loss 0.370127409696579\n",
      "cutpoint 0.04720102250576019\n",
      "214\n",
      "loss 0.3758261799812317\n",
      "cutpoint 0.0434357151389122\n",
      "215\n",
      "loss 0.3773004412651062\n",
      "cutpoint 0.04145807772874832\n",
      "216\n",
      "loss 0.3781132102012634\n",
      "cutpoint 0.040790677070617676\n",
      "217\n",
      "loss 0.3763648271560669\n",
      "cutpoint 0.04254193231463432\n",
      "218\n",
      "loss 0.3749881386756897\n",
      "cutpoint 0.0436805821955204\n",
      "219\n",
      "loss 0.3695538640022278\n",
      "cutpoint 0.0471256747841835\n",
      "220\n",
      "loss 0.36973845958709717\n",
      "cutpoint 0.04778237268328667\n",
      "221\n",
      "loss 0.368506520986557\n",
      "cutpoint 0.049921587109565735\n",
      "222\n",
      "loss 0.3681420385837555\n",
      "cutpoint 0.052837904542684555\n",
      "223\n",
      "loss 0.3704451322555542\n",
      "cutpoint 0.05567658320069313\n",
      "224\n",
      "loss 0.37552616000175476\n",
      "cutpoint 0.05866008624434471\n",
      "225\n",
      "loss 0.37734711170196533\n",
      "cutpoint 0.05924801528453827\n",
      "226\n",
      "loss 0.37533241510391235\n",
      "cutpoint 0.05862133204936981\n",
      "227\n",
      "loss 0.3706586956977844\n",
      "cutpoint 0.05621137470006943\n",
      "228\n",
      "loss 0.36777621507644653\n",
      "cutpoint 0.05328238382935524\n",
      "229\n",
      "loss 0.3681233525276184\n",
      "cutpoint 0.04993860051035881\n",
      "230\n",
      "loss 0.369169145822525\n",
      "cutpoint 0.04784741252660751\n",
      "231\n",
      "loss 0.36933577060699463\n",
      "cutpoint 0.04723275452852249\n",
      "232\n",
      "loss 0.37282681465148926\n",
      "cutpoint 0.04424717277288437\n",
      "233\n",
      "loss 0.37472784519195557\n",
      "cutpoint 0.04351695626974106\n",
      "234\n",
      "loss 0.37169474363327026\n",
      "cutpoint 0.044632431119680405\n",
      "235\n",
      "loss 0.3694525361061096\n",
      "cutpoint 0.047595638781785965\n",
      "236\n",
      "loss 0.36845293641090393\n",
      "cutpoint 0.05154736340045929\n",
      "237\n",
      "loss 0.3695230484008789\n",
      "cutpoint 0.055180929601192474\n",
      "238\n",
      "loss 0.37200722098350525\n",
      "cutpoint 0.057540375739336014\n",
      "239\n",
      "loss 0.37132465839385986\n",
      "cutpoint 0.05733463540673256\n",
      "240\n",
      "loss 0.36927270889282227\n",
      "cutpoint 0.054895251989364624\n",
      "241\n",
      "loss 0.3672148585319519\n",
      "cutpoint 0.05239775776863098\n",
      "242\n",
      "loss 0.36775028705596924\n",
      "cutpoint 0.05037033557891846\n",
      "243\n",
      "loss 0.36834418773651123\n",
      "cutpoint 0.047045595943927765\n",
      "244\n",
      "loss 0.37501558661460876\n",
      "cutpoint 0.04219839349389076\n",
      "245\n",
      "loss 0.3786877393722534\n",
      "cutpoint 0.03795964643359184\n",
      "246\n",
      "loss 0.38156864047050476\n",
      "cutpoint 0.03447827696800232\n",
      "247\n",
      "loss 0.3876124918460846\n",
      "cutpoint 0.031026724725961685\n",
      "248\n",
      "loss 0.38849449157714844\n",
      "cutpoint 0.03076639212667942\n",
      "249\n",
      "loss 0.38372713327407837\n",
      "cutpoint 0.03302949294447899\n"
     ]
    }
   ],
   "source": [
    "from multilevel_cutpoint_model import CutpointModel\n",
    "\n",
    "m = CutpointModel(X_train, t_train, s_train, sigmoid_temperature = 0.0001, depth = 0, iterations = 250, prior_strength = 0.3)\n",
    "m.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot_result(t_train[s_train==1], t_train[s_train==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_ci(cutpoints, model, X_test_in, t_test_in, s_test_in, t_train_in):\n",
    "    s_test = torch.from_numpy(s_test_in).float()\n",
    "    X_test = torch.from_numpy(X_test_in).float()\n",
    "    t_test = torch.from_numpy(t_test_in).float()\n",
    "    t_train = torch.from_numpy(t_train_in).float()\n",
    "\n",
    "    # predicted bucket probabilities for test data\n",
    "\n",
    "    # move pred to it's own class function, call it outside of this and just pass in the predictions\n",
    "    pred = model(X_test).detach().numpy()    \n",
    "    \n",
    "    # cdfs\n",
    "    t_pred_cdf = np.cumsum(pred, axis=1) \n",
    "\n",
    "    bucket_boundaries = [0] + sorted([i.item() for i in cutpoints]) + [1]\n",
    "    # rescale\n",
    "    bucket_boundaries = [boundary_i * (max(t_train) - min(t_train)) + min(t_train) \n",
    "                             for boundary_i in bucket_boundaries]\n",
    "    \n",
    "    N = len(pred)\n",
    "    n_buckets = len(bucket_boundaries) - 1\n",
    "\n",
    "    # one hot vector for where the 1 is in the most likely bucket\n",
    "    t_true_idx = np.zeros((N, n_buckets),dtype=int)\n",
    "    for ii in range(N):\n",
    "        for jj in range(n_buckets):\n",
    "            if t_test[ii] < bucket_boundaries[jj+1]:\n",
    "                t_true_idx[ii][jj] = 1\n",
    "                break\n",
    "           \n",
    "    print(bucket_boundaries[0:10])\n",
    "    print(t_test[0:10])\n",
    "    print(t_true_idx[0:10])\n",
    "    \n",
    "    t_true_idx = np.argmax(t_true_idx, axis=1)\n",
    "    concordant = 0\n",
    "    total = 0\n",
    "\n",
    "\n",
    "    idx = np.arange(N)\n",
    "\n",
    "    \n",
    "    \n",
    "    for i in range(N):\n",
    "\n",
    "        if s_test[i] == 0:\n",
    "            continue\n",
    "\n",
    "        # time bucket of observation for i, then for all but i\n",
    "        tti_idx = t_true_idx[i]\n",
    "        \n",
    "        tt_idx = t_true_idx[idx != i]\n",
    "\n",
    "        # calculate predicted risk for i at the time of their event\n",
    "        tpi = t_pred_cdf[i, tti_idx]\n",
    "\n",
    "\n",
    "        # predicted risk at that time for all but i\n",
    "        tp = t_pred_cdf[idx != tti_idx, tti_idx]\n",
    "\n",
    "        \n",
    "        total += np.sum(tti_idx < tt_idx) # observed in i first\n",
    "\n",
    "        concordant += np.sum((tti_idx < tt_idx) * (tpi > tp)) # and i predicted as higher risk\n",
    "\n",
    "    return concordant / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_ci(m.cutpoints, m.layers[-1], X_test, t_test, s_test, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_ci(m.cutpoint0, m.layers[-1], X_test, t_test, s_test, t_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_ci(torch.tensor([0.5]), m.layers[-1], X_test, t_test, s_test, t_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tri-modal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shifted and scaled sigmoid function\n",
    "def test_sigmoid(x, a=0, b=1.):\n",
    "    return 1 / (1 + (np.exp(-1 * (x - a) / b)))\n",
    "\n",
    "N = 10000\n",
    "P = 5\n",
    "\n",
    "rs = np.random.RandomState(1978)\n",
    "\n",
    "X = rs.randn(N, P)\n",
    "w = rs.randn(P)\n",
    "\n",
    "y_prob = test_sigmoid(X @ w)\n",
    "y = (rs.rand(N) < y_prob).astype(int)\n",
    "t = (rs.randn(N) + 5 * y + (rs.rand(N)> 0.5) * 5 * y )\n",
    "\n",
    "# make times positive\n",
    "t += abs(min(t))\n",
    "\n",
    "plt.hist(t[y==0], bins=50, alpha = 0.5, color = \"blue\", label=\"False\")\n",
    "plt.hist(t[y==1], bins=50, alpha = 0.5, color = \"red\", label=\"True\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = CutpointModel(X, t, y, X, t, y, depth = 1, iterations = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in m.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.cutpoint0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in m.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot_result(t[y==1], t[y==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_ci(m.cutpoints, m.layers[-1], X, t, y, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_ci(m.cutpoint0, m.layers[-1], X, t, y, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_ci(torch.tensor([0.9, 0.99, 0.999]), m.layers[-1], X, t, y, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## more modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "P = 5\n",
    "\n",
    "rs = np.random.RandomState(1978)\n",
    "# python please I want a do while loop\n",
    "\n",
    "X = rs.randn(N, P)\n",
    "w = rs.randn(P)\n",
    "\n",
    "y_prob = test_sigmoid(X @ w)\n",
    "y = (rs.rand(N) < y_prob).astype(int)\n",
    "t = (rs.randn(N) + 5 * y )\n",
    "\n",
    "\n",
    "for i in range(0, 3):\n",
    "    X_i = rs.randn(N, P)\n",
    "    w_i = rs.randn(P)\n",
    "\n",
    "    y_prob = test_sigmoid(X_i @ w_i)\n",
    "    y_i = (rs.rand(N) < y_prob).astype(int)\n",
    "    t_i = (rs.randn(N) + 20 * i + 5 * y_i )\n",
    "    X = np.concatenate((X, X_i))\n",
    "    t = np.concatenate((t, t_i))\n",
    "    y = np.concatenate((y, y_i))\n",
    "    \n",
    "\n",
    "# make times positive\n",
    "t += abs(min(t))\n",
    "\n",
    "plt.hist(t[y==0], bins=50, alpha = 0.5, color = \"blue\", label=\"False\")\n",
    "plt.hist(t[y==1], bins=50, alpha = 0.5, color = \"red\", label=\"True\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Model(X, t, depth = 2, iterations = 1000)\n",
    "m.train()\n",
    "m.plot_result(t[y==1], t[y==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sksurv data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.datasets import load_breast_cancer\n",
    "\n",
    "data_x, data_y = load_breast_cancer()\n",
    "y_df = pd.DataFrame.from_records(data_y)\n",
    "\n",
    "# cut last covariates that are strings\n",
    "X = torch.tensor(data_x.iloc[:, 1:-3].values)\n",
    "\n",
    "t = torch.from_numpy(y_df[\"t.tdm\"].values)\n",
    "\n",
    "\n",
    "plt.hist(y_df[~y_df[\"e.tdm\"]][\"t.tdm\"], bins = 20, alpha=0.5, color=\"blue\", label=\"no metastases\")\n",
    "plt.hist(y_df[y_df[\"e.tdm\"]][\"t.tdm\"], bins = 20, alpha=0.5, color=\"red\", label=\"metastases\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = Model(X, t, depth = 1, iterations=1000)\n",
    "m.train()\n",
    "m.plot_result(y_df[y_df[\"e.tdm\"]][\"t.tdm\"], \n",
    "              y_df[~y_df[\"e.tdm\"]][\"t.tdm\"],\n",
    "             title=\"Breast Cancer Survival Distribution\",\n",
    "             label_true=\"metastases\",\n",
    "             label_false=\"no metastases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worcester Heart Attack Study\n",
    "\n",
    "The dataset has 500 samples and 14 features. The endpoint is death, which occurred for 215 patients (43.0%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.datasets import load_whas500\n",
    "\n",
    "data_x, data_y = load_whas500()\n",
    "y_df = pd.DataFrame.from_records(data_y)\n",
    "\n",
    "\n",
    "X = torch.tensor(data_x[[\"age\", \"bmi\", \"diasbp\", \"hr\", \"los\", \"sysbp\"]].values)\n",
    "\n",
    "t = torch.from_numpy(y_df[\"lenfol\"].values)\n",
    "plt.title(\"Worcester Heart Attack Study Followup Distribution\")\n",
    "plt.hist(t[~y_df[\"fstat\"].values], color=\"blue\", alpha = 0.5, label=\"Survived\")\n",
    "plt.hist(t[y_df[\"fstat\"].values], color=\"red\", alpha = 0.5, label = \"Died\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = Model(X, t, depth = 2, iterations=1000)\n",
    "m.train()\n",
    "m.plot_result(t[y_df[\"fstat\"].values], \n",
    "             t[~y_df[\"fstat\"].values],\n",
    "             title=\"Worcester Heart Attack Study Followup Distribution\",\n",
    "             label_true=\"Died\",\n",
    "             label_false=\"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NACD Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('http://pssp.srv.ualberta.ca/system/predictors/datasets/000/000/032/original/All_Data_updated_may2011_CLEANED.csv?1350302245')\n",
    "t = df[\"SURVIVAL\"]\n",
    "# make times positive\n",
    "t += abs(min(t))\n",
    "\n",
    "# censored: 1 is that they were censored 0 they experienced the event\n",
    "y = 1 - df[\"CENSORED\"]\n",
    "\n",
    "numrc_cols = df.nunique() > 2\n",
    "df.loc[:, numrc_cols] = (df.loc[:, numrc_cols] - df.loc[:, numrc_cols].mean()) / df.loc[:, numrc_cols].std()\n",
    "\n",
    "OUTCOMES = ['SURVIVAL', 'CENSORED']\n",
    "X = df.drop(OUTCOMES, axis=1).sample(frac=1, random_state=2021)\n",
    "X = X.values\n",
    "\n",
    "print('There are', X.shape[1], 'features')\n",
    "print(f\"There are {X.shape[0]} patients\")\n",
    "\n",
    "plt.hist(t[y==0], bins=50, alpha = 0.5, color = \"blue\", label=\"censored\")\n",
    "plt.hist(t[y==1], bins=50, alpha = 0.5, color = \"red\", label=\"endpoint\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Model(X, t, depth = 2, iterations = 1000)\n",
    "m.train()\n",
    "m.plot_result(t[y==1],\n",
    "              t[y==0],\n",
    "              title=\"NACD Survival Distribution\",\n",
    "              label_true = \"endpoint\",\n",
    "              label_false = \"censored\"\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILL_VALUES = {\n",
    "    'alb': 3.5,\n",
    "    'pafi': 333.3,\n",
    "    'bili': 1.01,\n",
    "    'crea': 1.01,\n",
    "    'bun': 6.51,\n",
    "    'wblc': 9.,\n",
    "    'urine': 2502.\n",
    "}\n",
    "\n",
    "TO_DROP = ['aps', 'sps', 'surv2m', 'surv6m', 'prg2m', 'prg6m', 'dnr', 'dnrday']\n",
    "TO_DROP = TO_DROP + ['sfdm2', 'hospdead']\n",
    "\n",
    "# load, drop columns, fill using specified fill values\n",
    "df = pd.read_csv('datasets/support2.csv').drop(TO_DROP,axis=1).fillna(value=FILL_VALUES)\n",
    "\n",
    "# get dummies for categorical vars\n",
    "df = pd.get_dummies(df, dummy_na=True)\n",
    "\n",
    "# fill remaining values to the median\n",
    "\n",
    "df = df.fillna(df.median())\n",
    "\n",
    "# standardize numeric columns\n",
    "\n",
    "numrc_cols = df.dtypes == 'float64'\n",
    "df.loc[:, numrc_cols] = (df.loc[:, numrc_cols] - df.loc[:, numrc_cols].mean()) / df.loc[:, numrc_cols].std()\n",
    "\n",
    "OUTCOMES = ['death', 'd.time']\n",
    "X = df.drop(OUTCOMES, axis=1).sample(frac=1, random_state=2021)\n",
    "X = X.values\n",
    "\n",
    "t = df[\"d.time\"]\n",
    "y = df['death']\n",
    "\n",
    "print('There are', X.shape[1], 'features')\n",
    "print(f'There are {X.shape[0]} patients')\n",
    "\n",
    "plt.hist(t[y==0], bins=50, alpha = 0.5, color = \"blue\", label=\"censored\")\n",
    "plt.hist(t[y==1], bins=50, alpha = 0.5, color = \"red\", label=\"death\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Model(X, t.values, depth = 2, iterations=1000)\n",
    "m.train()\n",
    "m.plot_result(t[y==1],\n",
    "              t[y==0],\n",
    "              title=\"Support Survival Distribution\",\n",
    "              label_true = \"endpoint\",\n",
    "              label_false = \"censored\"\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(m.theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(m.theta[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(m.theta[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(m.theta[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
